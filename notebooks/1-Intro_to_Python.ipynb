{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Primer on Python for Statistical Programming and Data Science\n",
    "\n",
    "### Chris Fonnesbeck\n",
    "Senior Quantitative Analyst, The New York Yankees\n",
    "\n",
    "---\n",
    "\n",
    "![python](http://imgs.xkcd.com/comics/python.png)\n",
    "\n",
    "(via [xkcd](http://imgs.xkcd.com/comics/python.png))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Python?\n",
    "\n",
    "Python is a modern, open source, object-oriented programming language, created by a Dutch programmer, Guido van Rossum. Officially, it is an **interpreted** scripting language (meaning that it is not compiled until it is run) for the C programming language; in fact, Python itself is coded in C (though there are other non-C implementations). Frequently, it is compared to languages like Perl and Ruby. It offers the power and flexibility of lower level (*i.e.* compiled) languages, without the steep learning curve, and without most of the associated programming overhead. The language is very clean and readable, and it is available for almost every modern computing platform.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why use Python for scientific programming?\n",
    "\n",
    "Python offers a number of advantages to scientists, both for experienced and novice programmers alike:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Free and open \n",
    "\n",
    "Python is released on all platforms under an open license (Python Software Foundation License), meaning that the language and its source is freely distributable. Not only does this keep costs down for scientists and universities operating  under a limited budget, but it also frees programmers from licensing concerns for any software they may develop. There is little reason to buy expensive licenses for software such as Matlab or Maple, when Python can provide the same functionality for free!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Powerful and easy to use\n",
    "\n",
    "Python is simultaneously powerful, flexible and easy to learn and use (in general, these qualities are traded off for a given programming language). Anything that can be coded in C, FORTRAN, or Java can be done in Python, almost always in fewer lines of code, and with fewer debugging headaches. Its standard library is extremely rich, including modules for string manipulation, regular expressions, file compression, mathematics, profiling and debugging (to name only a few). Unnecessary language constructs, such as `END` statements and brackets are absent, making the code terse, efficient, and easy to read. Finally, Python is object-oriented, which is an important programming paradigm particularly well-suited to scientific programming, which allows data structures to be abstracted in a natural way.\n",
    "\n",
    "> Python is a language that is very powerful for developers, but is also accessible to Astronomers\n",
    "-- Perry Greenfield"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dynamic typing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_variable = 42\n",
    "print(my_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_variable = 'Welcome to ENAR'\n",
    "print(my_variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python's syntax is clean and easy to read, often described as **runnable pseudocode**.\n",
    "\n",
    "#### Example: Numerical Integration\n",
    "\n",
    "As an example, consider a Python implementation of the **trapezoidal rule**, a method from numerical analysis for approximating a definite integral. Specifically, it allows us to approximate:\n",
    "\n",
    "$$\\int_a^b f(x) dx$$\n",
    "\n",
    "using the approximation:\n",
    "\n",
    "$$\\int_a^b f(x) dx \\approx h \\left[ \\sum_{i=0}^n f(a + ih)\\right]\\frac{f(b) + f(a)}{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a Python function that implements this approximation. Notice a few things:\n",
    "\n",
    "- no brackets, only whitespace\n",
    "- commenting with # symbols\n",
    "- functions can be passed as arguments to other functions\n",
    "- `for` loop can be expressed in a single line, using a **comprehension**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trapezoidal(func, from_a, to_b, n_intervals):\n",
    "    \n",
    "    # Calculate the width of each chunk\n",
    "    int_width = (to_b - from_a) / n_intervals\n",
    "    \n",
    "    # Loop using a comprehension\n",
    "    sum_y = sum(func(from_a + i*int_width) for i in range(n_intervals))\n",
    "     \n",
    "    sum_y += 0.5 * (func(from_a) + func(to_b))\n",
    "    \n",
    "    return sum_y * int_width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the `trapezoidal` function to approximate a polynomial function, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def some_polynomial_function(x):\n",
    "    return 2 * x**2 + 3 * x + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trapezoidal(some_polynomial_function, 1, 5, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive\n",
    "\n",
    "Python may be run interactively on the command line, in much the same way as Octave or R. Rather than compiling and running a particular program, commands may entered serially followed by the `Return` key. This is often useful for mathematical programming and debugging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extensible\n",
    "\n",
    "Python is often referred to as a “glue” language, meaning that it is a useful in a mixed-language environment. Frequently, programmers must interact with colleagues that operate in other programming languages, or use significant quantities of legacy code that would be problematic or expensive to re-code. Python was designed to interact with other programming languages, and in many cases C or FORTRAN code can be compiled directly into Python programs (using packages such as `f2py` or `cython`). Additionally, since Python is an interpreted language, it can sometimes be slow relative to its compiled cousins. In many cases this performance deficit is due to a short loop of code that runs thousands or millions of times. Such bottlenecks may be removed by coding a function in FORTRAN, C or Cython, and compiling it into a Python module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, let's time our `trapezoidal` function to see how fast it runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit trapezoidal(some_polynomial_function, 1, 5, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this function happened to be the bottleneck in our code, we could replace it with faster code using a different language, and call it from Python.\n",
    "\n",
    "Let's look at an implementation in Cython, which is a Python-like language that allows Python programmers to write fast code without having to write C/C++/Fortran directly. It looks much like Python code, but with type declarations. Cython code is translated it to C (or C++ or others), which is then compiled to create a Python extension that we can import and use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "cdef inline double fast_polynomial(double x):\n",
    "    return 2*x*x + 3*x + 1\n",
    "\n",
    "cpdef trapezodial_fast(double a, double b, int n):\n",
    "    cdef double h, x, sumy\n",
    "    cdef int i\n",
    "    h = (b-a)/n \n",
    "    sumy = 0\n",
    "    x=a\n",
    "    for i in range(n):\n",
    "        x += h\n",
    "        sumy += fast_polynomial(x)\n",
    "    sumy += 0.5*(fast_polynomial(a) + fast_polynomial(b))\n",
    "    return sumy*h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that it does the same thing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trapezodial_fast(1, 5, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Cython, we can achieve speedups of several orders of magnitude, often faster than hand-coded C code. In addtion, Cython is compatible with core scientific programming tools like NumPy and IPython.\n",
    "\n",
    "Cython has built-in support for multicore processing.\n",
    "\n",
    "Cython is used to varying degrees by other packages in the Python scientific stack, such as pandas, sympy, scikit-learn and SciPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit trapezodial_fast(1, 5, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The extensibility of Python makes it useful as a **glue language**, in mixed-language environments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third-party modules\n",
    "\n",
    "There is a vast body of Python modules created outside the auspices of the Python Software Foundation. These include utilities for database connectivity, mathematics, statistics, and charting/plotting. Some notables include:\n",
    "\n",
    "* ***NumPy***: Numerical Python (NumPy) is a set of extensions that provides the ability to specify and manipulate array data structures. It provides array manipulation and computational capabilities similar to those found in Matlab or Octave. \n",
    "* ***SciPy***: An open source library of scientific tools for Python, SciPy supplements the NumPy module. SciPy gathering a variety of high level science and engineering modules together as a single package. SciPy includes modules for graphics and plotting, optimization, integration, special functions, signal and image processing, genetic algorithms, ODE solvers, and others.\n",
    "* ***Matplotlib***: Matplotlib is a python 2D plotting library which produces publication-quality figures in a variety of hardcopy formats and interactive environments across platforms. Its syntax is very similar to Matlab. \n",
    "* ***Pandas***: A module that provides high-performance, easy-to-use data structures and data analysis tools. In particular, the `DataFrame` class is useful for spreadsheet-like representation and mannipulation of data. Also includes high-level plotting functionality.\n",
    "* ***IPython***: An enhanced Python shell, designed to increase the efficiency and usability of coding, testing and debugging Python. It includes both a Qt-based console and an interactive HTML notebook interface, both of which feature multiline editing, interactive plotting and syntax highlighting.\n",
    "\n",
    "![](images/ecosystem.png)\n",
    "(courtesy Jake Vanderplas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy\n",
    "\n",
    "xs = sympy.symbols('xs')\n",
    "\n",
    "polynomial = 2*xs*xs + 3*xs + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(polynomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integrated_polynomial = sympy.integrate(polynomial, (xs, 1, 5))\n",
    "integrated_polynomial.evalf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Idiomatic Python\n",
    "\n",
    "Effective Python programming involves applying particular Python **idioms** effectively; these are idiosyncratic expressions that may only exist in Python (if you are coming from another language), but when used appropriately they can make your code more readable, faster, or both. You have seen some of these already -- for example, the **comprehension** as a means for succinctly implementing a `for` loop.\n",
    "\n",
    "### Comprehensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def do_math(x):\n",
    "    return 3 + x**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "squares = np.empty(1000000)\n",
    "for i in range(1000000):\n",
    "    squares[i] = do_math(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit squares = [do_math(i) for i in range(1000000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, not only is the list comprehension easier to write and read, it is also slightly faster.\n",
    "\n",
    "### Generators\n",
    "\n",
    "When you are dealing with a large number of elements that you do not need all at once, you can also consider another Python expression: the **generator**. For example, if we enclose the comprehension in parentheses instead of square brackets, we get a **generator expression** object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(i**2 for i in range(int(1e20)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, rather than storing 100,000,000,000,000,000,000,000 elements in memory, we can produce values as needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squares = (i**2 for i in range(int(1e10)))\n",
    "next(squares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(squares)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Built-in functions\n",
    "\n",
    "Before you go about coding your own functions, make sure that it isn't already provided as a **built-in function**. These are typically highly optimized, and written in C! [Here is a list of built-in functions](https://docs.python.org/3/library/functions.html).\n",
    "\n",
    "### String concatenation\n",
    "\n",
    "Just as you should avoid growing lists or arrays by concatenation or appending, iterating over strings and concatenating them manually is very inefficient. For example, let's say we want to concatente a list of strings into a single string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"Six\",\n",
    "\"days\",\n",
    "\"in\",\n",
    "\"to\",\n",
    "\"what\",\n",
    "\"should\",\n",
    "\"be\",\n",
    "\"a\",\n",
    "\"greatest\",\n",
    "\"two\",\n",
    "\"months\",\n",
    "\"of\",\n",
    "\"my\",\n",
    "\"life\",\n",
    "\"and\",\n",
    "\"it’s\",\n",
    "\"turned\",\n",
    "\"in\",\n",
    "\"to\",\n",
    "\"a\",\n",
    "\"nightmare\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One might be tempted to code the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"\"\n",
    "for word in words:\n",
    "    sentence += \" \" + word\n",
    "sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this is inefficient; since strings is immutable in Python, every `+` operation involves creating a new string and copying the old content. Instead, we can use the string method `join`, which is not only faster, but more flexible. Here, we would like to separate the words by spaces, which is easily done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' '.join(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avoid loops\n",
    "\n",
    "As we have seen, `for` loops in Python are slow. Wherever possible, avoid looping by using alternative strategies or vectorized operations. For example, say we wanted to return the common elements between two arrays. We might naively loop over both lists, comparing them elementwise to return their intersection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "list1 = np.random.choice(np.arange(20), replace=False, size=10)\n",
    "list2 = np.random.choice(np.arange(20), replace=False, size=10)\n",
    "\n",
    "def common_elements(a, b):\n",
    "    for i in a:\n",
    "        for j in b:\n",
    "            if i==j:\n",
    "                yield i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit list(common_elements(list1, list2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this involves two Python `for` loops and a conditional statement. Instead, we can use set operations on the built-in `set` type provided by Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit set(list1) & set(list2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Use NumPy\n",
    "\n",
    "Often, considerable performance gains can be achieved by replacing Python data structures and functions with corresponding NumPy versions. It provides a high-performance multidimensional array object, and tools for working with these arrays. \n",
    "\n",
    "This example, borrowed from NumPy creator Travis Oliphant, solves Laplace's equation over a 2-d rectangular grid using a simple iterative method. The code finds a two-dimensional function, u, where ∇2 u = 0, given some fixed boundary conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = 0.1\n",
    "dy = 0.1\n",
    "dx2 = dx*dx\n",
    "dy2 = dy*dy\n",
    "\n",
    "def py_update(u):\n",
    "    nx, ny = u.shape\n",
    "    for i in range(1,nx-1):\n",
    "        for j in range(1, ny-1):\n",
    "            u[i,j] = ((u[i+1, j] + u[i-1, j]) * dy2 +\n",
    "                      (u[i, j+1] + u[i, j-1]) * dx2) / (2*(dx2+dy2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc(N, Niter=100, func=py_update, args=()):\n",
    "    u = np.zeros([N, N])\n",
    "    u[0] = 1\n",
    "    for i in range(Niter):\n",
    "        func(u,*args)\n",
    "    return u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code takes a very long time to run in order to converge to the correct solution. For a 100x100 grid, visually-indistinguishable convergence occurs after about 8000 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit calc(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using NumPy, we can speed this code up significantly by using slicing and vectorized (automatic looping) calculations that replace the explicit loops in the Python-only solution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_update(u):\n",
    "    u[1:-1,1:-1] = ((u[2:,1:-1]+u[:-2,1:-1])*dy2 + \n",
    "                    (u[1:-1,2:] + u[1:-1,:-2])*dx2) / (2*(dx2+dy2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit calc(10, func=num_update)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Such speed-ups are not uncommon when using NumPy to replace Python loops where the inner loop is doing simple math on basic data-types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Survival Analysis\n",
    "\n",
    "To give you a feel for what using Python for data analysis is like, let's dive right in and look at a real-world example. This is a survival analysis of mastectomy data, based on an example by Austing Rochford of the PyMC3 team."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading libraries\n",
    "\n",
    "We use the **import** statement to load non-core modules into our Python environment. Packages with long names can be **aliased** to shorter names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas offers functions for automating the import of common data formats, such as comma-separated values (csv). Once imported, the data are stored in a tabular `DataFrame` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/mastectomy.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas offers functions and methods for cleaning and processing the data; for example, we want to recode all of our variables as numeric types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.event = df.event.astype(int)\n",
    "df.metastized = (df.metastized == 'yes').astype(int)\n",
    "n_patients = df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, we can summarize our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.event.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Data\n",
    "\n",
    "The mathematician Richard Hamming once said,\n",
    "\n",
    "> The purpose of computing is insight, not numbers\n",
    "\n",
    "and the best way to develop insight is often to visualize data. Visualization deserves an entire lecture (or course) of its own, but we can explore a few features of Python's `matplotlib` library here. \n",
    "\n",
    "While there is no \"official\" plotting library, this package is the *de facto* standard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Some IPython magic\n",
    ">\n",
    "> If you're using an IPython / Jupyter notebook,\n",
    "> you'll need to execute the following command\n",
    "> in order for your matplotlib images to appear\n",
    "> in the notebook:\n",
    ">\n",
    "> ```\n",
    "> % matplotlib inline\n",
    "> ```\n",
    ">  \n",
    "> The `%` indicates an IPython **magic function** -\n",
    "> a function that is only valid within the notebook environment.\n",
    "> Note that you only have to execute this function once per notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function plots the survival data, showing both the groups (metastized or not) and the events (or censoring).\n",
    "\n",
    "The `subplots` function creates a set of axes and a figure into which it is embedded. The function proceeds by drawing lines (`hlines`) and points (`scatter`) onto the axes, then adding labels and customizing the axes to best display survival information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_group_events(df, group_col, xlabel='', figsize=(8, 6)):\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    blue, _, green = sns.color_palette()[:3]\n",
    "    \n",
    "    patients = df.index.values\n",
    "\n",
    "    ax.hlines(patients[df[group_col].values == 1], 0, df[df[group_col].values == 1].time,\n",
    "              color=blue, label=group_col)\n",
    "\n",
    "    ax.hlines(patients[df[group_col].values == 0], 0, df[df[group_col].values == 0].time,\n",
    "              color=green, label='not ' + group_col)\n",
    "\n",
    "    ax.scatter(df[df.event.values == 1].time, patients[df.event.values == 1],\n",
    "               color='k', zorder=10, label='event')\n",
    "\n",
    "    ax.set_xlim(left=0)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_ylabel('Subject')\n",
    "\n",
    "    ax.set_ylim(-0.25, n_patients + 0.25)\n",
    "\n",
    "    ax.legend(loc='center right')\n",
    "    \n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_group_events(df, 'metastized', 'Months since mastectomy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bayesian proportional hazards model\n",
    "\n",
    "The two most basic estimators in survial analysis are the [Kaplan-Meier estimator](https://en.wikipedia.org/wiki/Kaplan%E2%80%93Meier_estimator) of the survival function and the [Nelson-Aalen estimator](https://en.wikipedia.org/wiki/Nelson%E2%80%93Aalen_estimator) of the cumulative hazard function.  However, since we want to understand the impact of metastization on survival time, a risk regression model is more appropriate.  Perhaps the most commonly used risk regression model is [Cox's proportional hazards model](https://en.wikipedia.org/wiki/Proportional_hazards_model).  In this model, if we have covariates $\\mathbf{x}$ and regression coefficients $\\beta$, the hazard rate is modeled as\n",
    "\n",
    "$$\\lambda(t) = \\lambda_0(t) \\exp(\\mathbf{x} \\beta).$$\n",
    "\n",
    "Here $\\lambda_0(t)$ is the baseline hazard, which is independent of the covariates $\\mathbf{x}$.  In this example, the covariates are the one-dimensonal vector `df.metastized`.\n",
    "    \n",
    "In order to perform Bayesian inference with the Cox model, we reparameterize it using a method called the **Poisson trick**, which changes the analysis from using time-to-event data to using count data. This requires us to partition the time range in question into intervals with endpoints $0 \\leq s_1 < s_2 < \\cdots < s_N$. With this partition, $\\lambda_0 (t) = \\lambda_j$ if $s_j \\leq t < s_{j + 1}$.  With $\\lambda_0(t)$ constrained to have this form, all we need to do is choose priors for the $N - 1$ values $\\lambda_j$.  We use independent vague priors $\\lambda_j \\sim \\operatorname{HalfCauchy}(1).$  For our mastectomy example, we make each interval three months long.\n",
    "\n",
    "We also must specify priors on $\\beta$ and $\\lambda_0(t)$.  We place a normal prior on $\\beta$, $\\beta \\sim N(\\mu_{\\beta}, \\sigma_{\\beta}^2),$ where $\\mu_{\\beta} \\sim N(0, 10^2)$ and $\\sigma_{\\beta} \\sim U(0, 10)$. The likelihood for the count data is a Poisson sampling distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `NumPy`'s functions to help us restructure our data to use the Poisson model. First, we can create a set of discrete time intervals of 3 months in length, using the `arange` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval_length = 3\n",
    "interval_bounds = np.arange(0, df.time.max() + interval_length + 1, interval_length)\n",
    "n_intervals = interval_bounds.size - 1\n",
    "intervals = np.arange(n_intervals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, our event data becomes a grid of patients and intervals, with a one in cells that a death occurs, and zero otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_period = np.floor((df.time - 0.01) / interval_length).astype(int)\n",
    "\n",
    "patients = df.index.values\n",
    "\n",
    "death = np.zeros((n_patients, n_intervals))\n",
    "death[patients, last_period] = df.event\n",
    "\n",
    "metastized = df.metastized.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "death"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To account for censoring and discretization, we also create an exposure variable that contains the number of months (0-3) in each interval that the patient was exposed to the risk of death."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exposure = np.greater_equal.outer(df.time, interval_bounds[:-1]) * interval_length\n",
    "exposure[patients, last_period] = df.time - interval_bounds[last_period]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exposure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the model using PyMC3, which allows us to specify the model and use Markov chain Monte Carlo (MCMC) to estimate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outer = pm.math.tt.outer\n",
    "\n",
    "with pm.Model() as model:\n",
    "\n",
    "    λ_0 = pm.HalfCauchy('λ_0', 1, shape=n_intervals)\n",
    "\n",
    "    α = pm.Normal('α', 0, sd=5)\n",
    "    β = pm.Normal('β', 0, sd=5)\n",
    "\n",
    "    λ = outer(pm.math.exp(α + β * metastized), λ_0)\n",
    "    μ = exposure * λ\n",
    "\n",
    "    obs = pm.Poisson('obs', μ, observed=death)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    \n",
    "    trace = pm.sample(1000, tune=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyMC3 includes a suite of functions for summarizing output, both in graphical and tabular forms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.summary(trace, ['β']).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_posterior(trace, varnames=['β'], color='#87ceeb');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Python\n",
    "\n",
    "How do you obtain and configure Python?\n",
    "\n",
    "Python comes pre-installed on some systems, but I recommend using the [Anaconda](https://www.anaconda.com) distribution because it includes enhancements that make configuring and maintaining Python on your computer much easier. Anaconda is freely available from the [Anaconda download page](https://www.anaconda.com/distribution/#download-section).\n",
    "\n",
    "![](images/anaconda.png)\n",
    "\n",
    "Download the Python 3.7 installer for your system, and execute the file, following the on-screen instructions.\n",
    "\n",
    "### System requirements\n",
    "\n",
    "- Operating system: Windows 7 or newer, 64-bit macOS 10.10+, or Linux, including Ubuntu, RedHat, CentOS 6+, and others.\n",
    "- If your operating system is older than what is currently supported, you can find older versions of the Anaconda installers in our archive that might work for you.\n",
    "- System architecture: Windows- 64-bit x86, 32-bit x86; MacOS- 64-bit x86; Linux- 64-bit x86, 64-bit Power8/Power9.\n",
    "- Minimum 5 GB disk space to download and install.\n",
    "\n",
    "On Windows, macOS, and Linux, it is best to install Anaconda for the local user, which does not require administrator permissions and is the most robust type of installation. \n",
    "\n",
    "During the installation, you will be asked if Anaconda should modify the PATH variable on your machine. It is recommended that you allow this, as it permits Anaconda to become the default Python installation on your machine, incase there are other versions already on your system.\n",
    "\n",
    "Once installed, you can run Python from either the native terminal (macOS or Linux) or the Anaconda Prompt (Windows).\n",
    "\n",
    "![](images/anaconda_python.png)\n",
    "\n",
    "### conda\n",
    "\n",
    "One of the great advantages to using the Anaconda Python distribution is the `conda` utility that is bundled with it. Conda is a powerful package manager and environment manager that you use with command line commands at the Anaconda Prompt for Windows, or in a terminal window for macOS or Linux.\n",
    "\n",
    "For example, we can use it to install third-party packages via `conda install`:\n",
    "\n",
    "![](images/conda_install.png)\n",
    "\n",
    "Or it can be used to update packages that are already installed:\n",
    "\n",
    "![](images/conda_update.png)\n",
    "\n",
    "And if you are unsure about whether a package is available in the Conda repository, you can search for it:\n",
    "\n",
    "![](images/conda_search.png)\n",
    "\n",
    "### conda environments\n",
    "\n",
    "Conda allows you to create separate environments containing files, packages and their dependencies that will not interact with other environments.\n",
    "\n",
    "When you begin using conda, you already have a default environment named base. You don't want to put programs into your base environment, though. Create separate environments to keep your programs isolated from each other.\n",
    "\n",
    "For example, we can create a new environment and install a package in it:\n",
    "\n",
    "![](images/conda_create.png)\n",
    "\n",
    "Conda will determine the dependencies of any package that you specify for installation, and install them as well. \n",
    "\n",
    "![](images/conda_env.png)\n",
    "\n",
    "Once created, Conda tells you how to activate the environment, via `conda activate`.\n",
    "\n",
    "![](images/conda_activate.png)\n",
    "\n",
    "The repository for this tutorial contains a file called `environment.yml` that includes a list of all the packages used for the tutorial. If you run\n",
    "\n",
    "    conda env create\n",
    "    \n",
    "in the directory containing `environment.yml` it will create the environment for you and install all of the packages listed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## To Learn More\n",
    "\n",
    "[Software Carpentry](http://software-carpentry.org/lessons.html) is a great place to learn Python if you are not already a programmer. Here are some additional resources:\n",
    "\n",
    "- Bassi S (2007) [A Primer on Python for Life Science Researchers](http://www.ploscompbiol.org/article/info%3Adoi%2F10.1371%2Fjournal.pcbi.0030199). PLoS Comput Biol 3(11): e199\n",
    "- [Scipy Lecture Notes](https://scipy-lectures.org/)\n",
    "- [Python Data Science Handbook](https://www.amazon.com/Python-Data-Science-Handbook-Essential/dp/1491912057), by Jake Vanderplas\n",
    "- [Data Science with Python](https://www.datacamp.com/tracks/data-scientist-with-python) from DataCamp"
   ]
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/f89ec8bc8271395c4466465802ba44a3"
  },
  "anaconda-cloud": {},
  "gist": {
   "data": {
    "description": "python/Introduction to Python.ipynb",
    "public": true
   },
   "id": "f89ec8bc8271395c4466465802ba44a3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
